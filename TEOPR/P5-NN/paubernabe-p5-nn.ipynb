{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-12-03T14:44:55.859969Z","iopub.status.busy":"2020-12-03T14:44:55.859Z","iopub.status.idle":"2020-12-03T14:45:11.004327Z","shell.execute_reply":"2020-12-03T14:45:11.003475Z"},"papermill":{"duration":15.171653,"end_time":"2020-12-03T14:45:11.004473","exception":false,"start_time":"2020-12-03T14:44:55.83282","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport imageio\nfrom skimage import transform,io\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/mlub-learning-to-count/train.txt\n/kaggle/input/mlub-learning-to-count/test/test/test_composite000000426.png\n/kaggle/input/mlub-learning-to-count/train/train/train_composite000012068.png\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-12-03T14:45:11.046605Z","iopub.status.busy":"2020-12-03T14:45:11.045811Z","iopub.status.idle":"2020-12-03T14:45:11.093805Z","shell.execute_reply":"2020-12-03T14:45:11.093126Z"},"papermill":{"duration":0.07151,"end_time":"2020-12-03T14:45:11.093943","exception":false,"start_time":"2020-12-03T14:45:11.022433","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/mlub-learning-to-count/train.txt',sep=' ',header=None)\nprint(df_train.shape)\n# take only the first 4000 images\n#df_train = df_train.head(4000)","execution_count":2,"outputs":[{"output_type":"stream","text":"(15000, 2)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Data augmentation\n\nPer a augmentar la mida del nostre dataset, hem utilitzat un procediment anomenat Data Augmentation per a generar noves dades del conjunt que disposem.\n\nEn el meu cas, he decidit fer rotacions de les imatges del dataframe. Encara que podem canviar la il·luminació, contrast, etc.\n\nD'aquesta manera, tenim un model que pot arribar a generalitzar millor gràcies a la varietat d'imatges sintètiques generades."},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nimport random\ndef data_augmentation(img, label, n_generated):\n    datagen = ImageDataGenerator(rotation_range=90)\n    data_augmentation = []\n    data = img_to_array(img)\n    samples = expand_dims(data, 0)\n    it = datagen.flow(samples, batch_size=1)\n    # generate samples and plot\n    for i in range(n_generated):\n        # generate batch of images\n        batch = it.next()\n        image = batch[0].astype('float64')\n        image = image[:,:,0]\n        data_augmentation.append((image, label))\n\n    listX = [x[0] for x in data_augmentation]\n    listy = [x[1] for x in data_augmentation]\n    return listX, listy","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '/kaggle/input/mlub-learning-to-count/train/'\nim_size = 64\nX_aug = []\ny_aug = []\ngenerated_images = 1\nfor ind, item in df_train.iterrows():\n    im  = imageio.imread(data_dir + item[0])/255.\n    listx, listy = data_augmentation(im, item[1], generated_images)\n    for im in range(len(listx)):\n        small_im = transform.resize(listx[im], (im_size,im_size), mode='symmetric', preserve_range=True)\n        X_aug.append(small_im)\n        y_aug.append(listy[im])\n    \n    ","execution_count":4,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:45:11.139536Z","iopub.status.busy":"2020-12-03T14:45:11.138736Z","iopub.status.idle":"2020-12-03T14:45:17.05911Z","shell.execute_reply":"2020-12-03T14:45:17.058356Z"},"papermill":{"duration":5.948509,"end_time":"2020-12-03T14:45:17.059263","exception":false,"start_time":"2020-12-03T14:45:11.110754","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# read images and store into a np array\n\nim_size = 64\nN = df_train.shape[0]\nX = np.zeros((N, im_size,im_size))\ny = np.zeros((N))\ncont =0\n\nfor ind, item in df_train.iterrows():\n    im       = imageio.imread(data_dir + item[0])/255.\n    small_im = transform.resize(im, (im_size,im_size), mode='symmetric', preserve_range=True)\n    X[cont, :,:] = small_im\n    y[cont] = item[1]\n    cont+=1\n\nplt.imshow(small_im,cmap='gray')\nplt.show()","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.concatenate((X, X_aug))\ny = np.concatenate((y, y_aug))","execution_count":6,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:45:17.101852Z","iopub.status.busy":"2020-12-03T14:45:17.100838Z","iopub.status.idle":"2020-12-03T14:45:17.373378Z","shell.execute_reply":"2020-12-03T14:45:17.372593Z"},"papermill":{"duration":0.296318,"end_time":"2020-12-03T14:45:17.373508","exception":false,"start_time":"2020-12-03T14:45:17.07719","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val= train_test_split(X, y, test_size=0.3, random_state=66)","execution_count":7,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:45:17.418451Z","iopub.status.busy":"2020-12-03T14:45:17.417641Z","iopub.status.idle":"2020-12-03T14:46:03.746644Z","shell.execute_reply":"2020-12-03T14:46:03.745944Z"},"papermill":{"duration":46.354152,"end_time":"2020-12-03T14:46:03.746786","exception":false,"start_time":"2020-12-03T14:45:17.392634","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n# random forest model \n'''rfc = RandomForestRegressor()\nrfc.fit(X_train.reshape((X_train.shape[0],-1)),y_train)\n# predictions\nrfc_predict = rfc.predict(X_val.reshape((X_val.shape[0],-1)))\n'''","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"'rfc = RandomForestRegressor()\\nrfc.fit(X_train.reshape((X_train.shape[0],-1)),y_train)\\n# predictions\\nrfc_predict = rfc.predict(X_val.reshape((X_val.shape[0],-1)))\\n'"},"metadata":{}}]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:46:03.795796Z","iopub.status.busy":"2020-12-03T14:46:03.794714Z","iopub.status.idle":"2020-12-03T14:46:04.000114Z","shell.execute_reply":"2020-12-03T14:46:03.999281Z"},"papermill":{"duration":0.235178,"end_time":"2020-12-03T14:46:04.000269","exception":false,"start_time":"2020-12-03T14:46:03.765091","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n'''plt.plot(rfc_predict,y_val,'.')\n\nprint(np.sqrt(mean_squared_error(rfc_predict,y_val)))'''","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"\"plt.plot(rfc_predict,y_val,'.')\\n\\nprint(np.sqrt(mean_squared_error(rfc_predict,y_val)))\""},"metadata":{}}]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:46:04.048579Z","iopub.status.busy":"2020-12-03T14:46:04.047774Z","iopub.status.idle":"2020-12-03T14:46:10.291099Z","shell.execute_reply":"2020-12-03T14:46:10.290194Z"},"papermill":{"duration":6.269311,"end_time":"2020-12-03T14:46:10.291253","exception":false,"start_time":"2020-12-03T14:46:04.021942","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\nhistory = {}","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train[..., np.newaxis]\nX_val = X_val[..., np.newaxis]","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convolutional Neural Network\n\nPer al nostre model utilitzarem una CNN, perquè estem tractant amb imatges i aquest tipus de NN s'adapta millor a l'anàlisi d'imatges i les seves principals característiques."},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\n\nDefaultConv2D = partial(keras.layers.Conv2D,\n                        kernel_size=3, activation='relu', padding=\"SAME\")\nmodel = keras.models.Sequential([\n    DefaultConv2D(filters=32, kernel_size=5, input_shape=[64, 64, 1], kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Dropout(0.2),\n    DefaultConv2D(filters=64, kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Dropout(0.2),\n    DefaultConv2D(filters=64, kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n    DefaultConv2D(filters=96, kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(units=256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(units=100, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(units=64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(units=1, activation='linear',kernel_regularizer=keras.regularizers.l2(0.001))\n])","execution_count":12,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:46:10.537118Z","iopub.status.busy":"2020-12-03T14:46:10.535928Z","iopub.status.idle":"2020-12-03T14:46:10.54284Z","shell.execute_reply":"2020-12-03T14:46:10.542145Z"},"papermill":{"duration":0.03872,"end_time":"2020-12-03T14:46:10.542983","exception":false,"start_time":"2020-12-03T14:46:10.504263","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model.layers","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f0badb81790>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad3403d0>,\n <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f0bad340b50>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad340ed0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f0bad340090>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad305750>,\n <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f0bad305c10>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad305fd0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f0bad3091d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad3098d0>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad309d50>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f0bad309f10>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad30d610>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad30dad0>,\n <tensorflow.python.keras.layers.core.Flatten at 0x7f0bad340590>,\n <tensorflow.python.keras.layers.core.Dense at 0x7f0bad30ded0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad312350>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad312750>,\n <tensorflow.python.keras.layers.core.Dense at 0x7f0bad312910>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad312d50>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad319210>,\n <tensorflow.python.keras.layers.core.Dense at 0x7f0bad3193d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f0bad319850>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7f0bad319c90>,\n <tensorflow.python.keras.layers.core.Dense at 0x7f0bae735150>]"},"metadata":{}}]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:46:10.597751Z","iopub.status.busy":"2020-12-03T14:46:10.596294Z","iopub.status.idle":"2020-12-03T14:46:10.603483Z","shell.execute_reply":"2020-12-03T14:46:10.604371Z"},"papermill":{"duration":0.0385,"end_time":"2020-12-03T14:46:10.604599","exception":false,"start_time":"2020-12-03T14:46:10.566099","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 32)        832       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 64, 64, 32)        128       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 16, 16, 64)        256       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 96)        55392     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 16, 16, 96)        384       \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 16, 16, 96)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 24576)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               6291712   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 256)               1024      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 100)               25700     \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 100)               400       \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                6464      \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 64)                256       \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 6,438,293\nTrainable params: 6,436,941\nNon-trainable params: 1,352\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:46:10.667202Z","iopub.status.busy":"2020-12-03T14:46:10.66588Z","iopub.status.idle":"2020-12-03T14:46:10.674214Z","shell.execute_reply":"2020-12-03T14:46:10.67354Z"},"papermill":{"duration":0.046153,"end_time":"2020-12-03T14:46:10.674362","exception":false,"start_time":"2020-12-03T14:46:10.628209","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def lr_schedule(epoch):\n    \"\"\"Learning Rate Schedule\n\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n\n    # Arguments\n        epoch (int): The number of epochs\n\n    # Returns\n        lr (float32): learning rate\n    \"\"\"\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr\ncallback = keras.callbacks.LearningRateScheduler(lr_schedule)\nmodel.compile(loss=\"mse\",\n              optimizer=\"adam\",\n              metrics=[\"accuracy\"])","execution_count":15,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:46:10.724901Z","iopub.status.busy":"2020-12-03T14:46:10.723423Z","iopub.status.idle":"2020-12-03T14:47:25.607805Z","shell.execute_reply":"2020-12-03T14:47:25.607059Z"},"papermill":{"duration":74.911926,"end_time":"2020-12-03T14:47:25.607936","exception":false,"start_time":"2020-12-03T14:46:10.69601","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=200,\n                    validation_data=(X_val, y_val),verbose=1, batch_size=128, callbacks = [callback])","execution_count":null,"outputs":[{"output_type":"stream","text":"Learning rate:  0.001\nEpoch 1/200\n165/165 [==============================] - 4s 25ms/step - loss: 186.5852 - accuracy: 0.0342 - val_loss: 729.5668 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 2/200\n165/165 [==============================] - 4s 22ms/step - loss: 71.2320 - accuracy: 0.0342 - val_loss: 520.5820 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 3/200\n165/165 [==============================] - 3s 21ms/step - loss: 15.3423 - accuracy: 0.0364 - val_loss: 1267.7919 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 4/200\n165/165 [==============================] - 4s 22ms/step - loss: 11.1764 - accuracy: 0.0353 - val_loss: 156.9900 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 5/200\n165/165 [==============================] - 3s 21ms/step - loss: 10.0686 - accuracy: 0.0355 - val_loss: 709.2454 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 6/200\n165/165 [==============================] - 3s 21ms/step - loss: 9.6643 - accuracy: 0.0373 - val_loss: 5.8714 - val_accuracy: 0.0420\nLearning rate:  0.001\nEpoch 7/200\n165/165 [==============================] - 4s 23ms/step - loss: 9.2794 - accuracy: 0.0363 - val_loss: 485.0811 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 8/200\n165/165 [==============================] - 4s 22ms/step - loss: 8.8246 - accuracy: 0.0368 - val_loss: 527.6990 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 9/200\n165/165 [==============================] - 4s 21ms/step - loss: 8.4888 - accuracy: 0.0363 - val_loss: 318.3006 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 10/200\n165/165 [==============================] - 4s 22ms/step - loss: 7.9367 - accuracy: 0.0364 - val_loss: 94.8821 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 11/200\n165/165 [==============================] - 4s 22ms/step - loss: 7.6732 - accuracy: 0.0346 - val_loss: 7.9453 - val_accuracy: 0.0334\nLearning rate:  0.001\nEpoch 12/200\n165/165 [==============================] - 3s 21ms/step - loss: 7.1300 - accuracy: 0.0376 - val_loss: 4.7100 - val_accuracy: 0.0492\nLearning rate:  0.001\nEpoch 13/200\n165/165 [==============================] - 4s 22ms/step - loss: 7.0390 - accuracy: 0.0364 - val_loss: 18.9654 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 14/200\n165/165 [==============================] - 4s 21ms/step - loss: 7.0753 - accuracy: 0.0357 - val_loss: 91.3176 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 15/200\n165/165 [==============================] - 3s 21ms/step - loss: 6.5600 - accuracy: 0.0384 - val_loss: 5.1119 - val_accuracy: 0.0366\nLearning rate:  0.001\nEpoch 16/200\n165/165 [==============================] - 4s 21ms/step - loss: 6.6640 - accuracy: 0.0361 - val_loss: 7.1389 - val_accuracy: 0.0544\nLearning rate:  0.001\nEpoch 17/200\n165/165 [==============================] - 3s 21ms/step - loss: 6.2761 - accuracy: 0.0380 - val_loss: 34.5849 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 18/200\n165/165 [==============================] - 3s 21ms/step - loss: 6.2200 - accuracy: 0.0377 - val_loss: 23.2447 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 19/200\n165/165 [==============================] - 4s 22ms/step - loss: 6.2061 - accuracy: 0.0374 - val_loss: 4.6373 - val_accuracy: 0.0544\nLearning rate:  0.001\nEpoch 20/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.9338 - accuracy: 0.0379 - val_loss: 124.9948 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 21/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.9062 - accuracy: 0.0384 - val_loss: 7.2719 - val_accuracy: 0.0374\nLearning rate:  0.001\nEpoch 22/200\n165/165 [==============================] - 4s 21ms/step - loss: 5.6787 - accuracy: 0.0388 - val_loss: 22.1590 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 23/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.7061 - accuracy: 0.0395 - val_loss: 91.9186 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 24/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.7485 - accuracy: 0.0379 - val_loss: 90.3970 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 25/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.6710 - accuracy: 0.0381 - val_loss: 39.2530 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 26/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4398 - accuracy: 0.0392 - val_loss: 370.5741 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 27/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.7161 - accuracy: 0.0388 - val_loss: 28.3770 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 28/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.5742 - accuracy: 0.0379 - val_loss: 29.3109 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 29/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.4717 - accuracy: 0.0392 - val_loss: 241.0508 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 30/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4032 - accuracy: 0.0388 - val_loss: 33.7853 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 31/200\n165/165 [==============================] - 4s 21ms/step - loss: 5.3872 - accuracy: 0.0386 - val_loss: 199.9050 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 32/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4329 - accuracy: 0.0378 - val_loss: 58.5368 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 33/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4738 - accuracy: 0.0392 - val_loss: 159.9303 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 34/200\n165/165 [==============================] - 4s 21ms/step - loss: 5.5277 - accuracy: 0.0397 - val_loss: 180.1597 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 35/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4352 - accuracy: 0.0390 - val_loss: 1094.9342 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 36/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.5491 - accuracy: 0.0387 - val_loss: 128.7271 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 37/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4151 - accuracy: 0.0392 - val_loss: 113.3022 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 38/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.6866 - accuracy: 0.0390 - val_loss: 307.0472 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 39/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.3816 - accuracy: 0.0396 - val_loss: 21.2110 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 40/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1489 - accuracy: 0.0397 - val_loss: 25.2819 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 41/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1202 - accuracy: 0.0381 - val_loss: 56.5361 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 42/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1959 - accuracy: 0.0398 - val_loss: 5.7470 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 43/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.0680 - accuracy: 0.0391 - val_loss: 144.7898 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 44/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1535 - accuracy: 0.0379 - val_loss: 68.1940 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 45/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.0640 - accuracy: 0.0389 - val_loss: 3.4789 - val_accuracy: 0.0371\nLearning rate:  0.001\nEpoch 46/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1886 - accuracy: 0.0386 - val_loss: 563.2994 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 47/200\n165/165 [==============================] - 4s 22ms/step - loss: 6.7665 - accuracy: 0.0373 - val_loss: 4.7799 - val_accuracy: 0.0366\nLearning rate:  0.001\nEpoch 48/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.7080 - accuracy: 0.0378 - val_loss: 71.4077 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 49/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4514 - accuracy: 0.0394 - val_loss: 49.0283 - val_accuracy: 0.0343\n","name":"stdout"},{"output_type":"stream","text":"Learning rate:  0.001\nEpoch 50/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.4224 - accuracy: 0.0401 - val_loss: 48.0344 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 51/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.3857 - accuracy: 0.0391 - val_loss: 31.9575 - val_accuracy: 0.0336\nLearning rate:  0.001\nEpoch 52/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4393 - accuracy: 0.0373 - val_loss: 17.7121 - val_accuracy: 0.0380\nLearning rate:  0.001\nEpoch 53/200\n165/165 [==============================] - 4s 21ms/step - loss: 5.3672 - accuracy: 0.0388 - val_loss: 92.3123 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 54/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.2536 - accuracy: 0.0381 - val_loss: 22.3552 - val_accuracy: 0.0333\nLearning rate:  0.001\nEpoch 55/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.2791 - accuracy: 0.0366 - val_loss: 21.4049 - val_accuracy: 0.0449\nLearning rate:  0.001\nEpoch 56/200\n165/165 [==============================] - 4s 23ms/step - loss: 5.2362 - accuracy: 0.0383 - val_loss: 32.0313 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 57/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1935 - accuracy: 0.0403 - val_loss: 3.7377 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 58/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1577 - accuracy: 0.0384 - val_loss: 21.0809 - val_accuracy: 0.0444\nLearning rate:  0.001\nEpoch 59/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1359 - accuracy: 0.0398 - val_loss: 4.7018 - val_accuracy: 0.0530\nLearning rate:  0.001\nEpoch 60/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1981 - accuracy: 0.0385 - val_loss: 43.4533 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 61/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.0853 - accuracy: 0.0393 - val_loss: 8.5373 - val_accuracy: 0.0346\nLearning rate:  0.001\nEpoch 62/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.0612 - accuracy: 0.0386 - val_loss: 82.6130 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 63/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1178 - accuracy: 0.0385 - val_loss: 30.7853 - val_accuracy: 0.0334\nLearning rate:  0.001\nEpoch 64/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1533 - accuracy: 0.0402 - val_loss: 48.2658 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 65/200\n165/165 [==============================] - 4s 23ms/step - loss: 5.1800 - accuracy: 0.0387 - val_loss: 9.4576 - val_accuracy: 0.0394\nLearning rate:  0.001\nEpoch 66/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.9471 - accuracy: 0.0390 - val_loss: 254.6460 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 67/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.4756 - accuracy: 0.0385 - val_loss: 125.2805 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 68/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1132 - accuracy: 0.0380 - val_loss: 6.0346 - val_accuracy: 0.0568\nLearning rate:  0.001\nEpoch 69/200\n165/165 [==============================] - 4s 21ms/step - loss: 4.9760 - accuracy: 0.0395 - val_loss: 81.8062 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 70/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1245 - accuracy: 0.0383 - val_loss: 13.9291 - val_accuracy: 0.0378\nLearning rate:  0.001\nEpoch 71/200\n165/165 [==============================] - 3s 21ms/step - loss: 5.1839 - accuracy: 0.0380 - val_loss: 14.6987 - val_accuracy: 0.0386\nLearning rate:  0.001\nEpoch 72/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.1289 - accuracy: 0.0373 - val_loss: 56.7871 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 73/200\n165/165 [==============================] - 4s 21ms/step - loss: 4.8668 - accuracy: 0.0384 - val_loss: 45.5289 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 74/200\n165/165 [==============================] - 4s 23ms/step - loss: 4.9977 - accuracy: 0.0390 - val_loss: 8.4251 - val_accuracy: 0.0344\nLearning rate:  0.001\nEpoch 75/200\n165/165 [==============================] - 4s 23ms/step - loss: 4.9263 - accuracy: 0.0387 - val_loss: 71.6624 - val_accuracy: 0.0332\nLearning rate:  0.001\nEpoch 76/200\n165/165 [==============================] - 4s 21ms/step - loss: 5.0577 - accuracy: 0.0407 - val_loss: 192.3065 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 77/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.8420 - accuracy: 0.0390 - val_loss: 4.2729 - val_accuracy: 0.0344\nLearning rate:  0.001\nEpoch 78/200\n165/165 [==============================] - 4s 21ms/step - loss: 4.9501 - accuracy: 0.0383 - val_loss: 26.9069 - val_accuracy: 0.0357\nLearning rate:  0.001\nEpoch 79/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.7728 - accuracy: 0.0395 - val_loss: 56.2379 - val_accuracy: 0.0343\nLearning rate:  0.001\nEpoch 80/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.8048 - accuracy: 0.0391 - val_loss: 7.7792 - val_accuracy: 0.0426\nLearning rate:  0.001\nEpoch 81/200\n165/165 [==============================] - 4s 22ms/step - loss: 5.0617 - accuracy: 0.0392 - val_loss: 3.7245 - val_accuracy: 0.0366\nLearning rate:  0.0001\nEpoch 82/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.4517 - accuracy: 0.0393 - val_loss: 3.8413 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 83/200\n165/165 [==============================] - 4s 22ms/step - loss: 4.4803 - accuracy: 0.0401 - val_loss: 2.8261 - val_accuracy: 0.0348\nLearning rate:  0.0001\nEpoch 84/200\n165/165 [==============================] - 4s 22ms/step - loss: 4.2006 - accuracy: 0.0390 - val_loss: 2.7804 - val_accuracy: 0.0387\nLearning rate:  0.0001\nEpoch 85/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.1817 - accuracy: 0.0386 - val_loss: 8.6620 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 86/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.2481 - accuracy: 0.0406 - val_loss: 2.7442 - val_accuracy: 0.0347\nLearning rate:  0.0001\nEpoch 87/200\n165/165 [==============================] - 4s 21ms/step - loss: 4.3059 - accuracy: 0.0387 - val_loss: 4.4145 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 88/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.1309 - accuracy: 0.0383 - val_loss: 5.4272 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 89/200\n165/165 [==============================] - 3s 21ms/step - loss: 4.0678 - accuracy: 0.0388 - val_loss: 4.3144 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 90/200\n165/165 [==============================] - 4s 21ms/step - loss: 4.0172 - accuracy: 0.0400 - val_loss: 3.6439 - val_accuracy: 0.0344\nLearning rate:  0.0001\nEpoch 91/200\n165/165 [==============================] - 4s 22ms/step - loss: 4.0238 - accuracy: 0.0413 - val_loss: 2.8915 - val_accuracy: 0.0573\nLearning rate:  0.0001\nEpoch 92/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.9200 - accuracy: 0.0406 - val_loss: 2.5480 - val_accuracy: 0.0350\nLearning rate:  0.0001\nEpoch 93/200\n165/165 [==============================] - 4s 23ms/step - loss: 4.0654 - accuracy: 0.0410 - val_loss: 4.8701 - val_accuracy: 0.0344\nLearning rate:  0.0001\nEpoch 94/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.9337 - accuracy: 0.0400 - val_loss: 8.2345 - val_accuracy: 0.0359\nLearning rate:  0.0001\nEpoch 95/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.8795 - accuracy: 0.0398 - val_loss: 2.9862 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 96/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.9689 - accuracy: 0.0403 - val_loss: 2.7210 - val_accuracy: 0.0368\nLearning rate:  0.0001\nEpoch 97/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.8185 - accuracy: 0.0405 - val_loss: 3.4153 - val_accuracy: 0.0656\nLearning rate:  0.0001\nEpoch 98/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.9015 - accuracy: 0.0395 - val_loss: 6.4723 - val_accuracy: 0.0411\n","name":"stdout"},{"output_type":"stream","text":"Learning rate:  0.0001\nEpoch 99/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.8325 - accuracy: 0.0390 - val_loss: 4.0388 - val_accuracy: 0.0344\nLearning rate:  0.0001\nEpoch 100/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.9103 - accuracy: 0.0410 - val_loss: 2.8456 - val_accuracy: 0.0358\nLearning rate:  0.0001\nEpoch 101/200\n165/165 [==============================] - 4s 21ms/step - loss: 4.0038 - accuracy: 0.0388 - val_loss: 7.5697 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 102/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.7955 - accuracy: 0.0392 - val_loss: 2.9493 - val_accuracy: 0.0532\nLearning rate:  0.0001\nEpoch 103/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.8237 - accuracy: 0.0394 - val_loss: 7.7189 - val_accuracy: 0.0344\nLearning rate:  0.0001\nEpoch 104/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.7403 - accuracy: 0.0401 - val_loss: 2.5591 - val_accuracy: 0.0388\nLearning rate:  0.0001\nEpoch 105/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.9625 - accuracy: 0.0403 - val_loss: 4.0458 - val_accuracy: 0.0348\nLearning rate:  0.0001\nEpoch 106/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.7866 - accuracy: 0.0401 - val_loss: 4.1331 - val_accuracy: 0.0513\nLearning rate:  0.0001\nEpoch 107/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.9942 - accuracy: 0.0386 - val_loss: 7.5343 - val_accuracy: 0.0376\nLearning rate:  0.0001\nEpoch 108/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.9662 - accuracy: 0.0392 - val_loss: 3.5301 - val_accuracy: 0.0536\nLearning rate:  0.0001\nEpoch 109/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.8786 - accuracy: 0.0404 - val_loss: 6.7482 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 110/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.7932 - accuracy: 0.0386 - val_loss: 3.9771 - val_accuracy: 0.0344\nLearning rate:  0.0001\nEpoch 111/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.8718 - accuracy: 0.0387 - val_loss: 7.9939 - val_accuracy: 0.0338\nLearning rate:  0.0001\nEpoch 112/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.8492 - accuracy: 0.0417 - val_loss: 2.4948 - val_accuracy: 0.0598\nLearning rate:  0.0001\nEpoch 113/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.7913 - accuracy: 0.0396 - val_loss: 7.1638 - val_accuracy: 0.0379\nLearning rate:  0.0001\nEpoch 114/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.7777 - accuracy: 0.0400 - val_loss: 2.5310 - val_accuracy: 0.0394\nLearning rate:  0.0001\nEpoch 115/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.8908 - accuracy: 0.0392 - val_loss: 2.5483 - val_accuracy: 0.0386\nLearning rate:  0.0001\nEpoch 116/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.6490 - accuracy: 0.0389 - val_loss: 6.2543 - val_accuracy: 0.0438\nLearning rate:  0.0001\nEpoch 117/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.7289 - accuracy: 0.0406 - val_loss: 8.5499 - val_accuracy: 0.0343\nLearning rate:  0.0001\nEpoch 118/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.8062 - accuracy: 0.0394 - val_loss: 2.8205 - val_accuracy: 0.0644\nLearning rate:  0.0001\nEpoch 119/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.7729 - accuracy: 0.0401 - val_loss: 5.1769 - val_accuracy: 0.0349\nLearning rate:  0.0001\nEpoch 120/200\n165/165 [==============================] - 4s 22ms/step - loss: 3.7621 - accuracy: 0.0397 - val_loss: 3.4879 - val_accuracy: 0.0519\nLearning rate:  0.0001\nEpoch 121/200\n165/165 [==============================] - 4s 21ms/step - loss: 3.5996 - accuracy: 0.0395 - val_loss: 2.8946 - val_accuracy: 0.0504\nLearning rate:  1e-05\nEpoch 122/200\n165/165 [==============================] - 3s 21ms/step - loss: 3.5369 - accuracy: 0.0411 - val_loss: 2.4453 - val_accuracy: 0.0647\nLearning rate:  1e-05\nEpoch 123/200\n163/165 [============================>.] - ETA: 0s - loss: 3.6423 - accuracy: 0.0404","name":"stdout"}]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:47:27.063246Z","iopub.status.busy":"2020-12-03T14:47:27.062434Z","iopub.status.idle":"2020-12-03T14:47:27.304624Z","shell.execute_reply":"2020-12-03T14:47:27.303977Z"},"papermill":{"duration":0.977212,"end_time":"2020-12-03T14:47:27.304759","exception":false,"start_time":"2020-12-03T14:47:26.327547","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history)[['loss','val_loss']].plot(figsize=(8, 5))\nplt.grid(True)\n#plt.gca().set_ylim(0.4, 0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot(figsize=(8, 5))\nplt.grid(True)\n#plt.gca().set_ylim(0.4, 0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:47:28.743875Z","iopub.status.busy":"2020-12-03T14:47:28.743144Z","iopub.status.idle":"2020-12-03T14:47:29.054322Z","shell.execute_reply":"2020-12-03T14:47:29.053629Z"},"papermill":{"duration":1.033473,"end_time":"2020-12-03T14:47:29.054451","exception":false,"start_time":"2020-12-03T14:47:28.020978","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import math\ny_model1 = model.predict(X_val)\nprint(y_val)\ny_model_output = []\nfor i in y_model1:\n    y_model_output.append(int(round(i[0])))\nplt.plot(y_model_output,y_val,'.')\nprint(y_model_output)\nnp.sqrt(mean_squared_error(y_model_output,y_val))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:47:30.560629Z","iopub.status.busy":"2020-12-03T14:47:30.559855Z","iopub.status.idle":"2020-12-03T14:47:34.469812Z","shell.execute_reply":"2020-12-03T14:47:34.470492Z"},"papermill":{"duration":4.700001,"end_time":"2020-12-03T14:47:34.470654","exception":false,"start_time":"2020-12-03T14:47:29.770653","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"## evaluate test and generate submission\ntest_dir = '/kaggle/input/mlub-learning-to-count/test/test/'\nim_size = 64\nN = 500\nX_test = np.zeros((N, im_size,im_size))\ncont =0\n\nfor x in range(500):\n    im       = imageio.imread(test_dir + 'test_composite'+str(x).zfill(9) + '.png')/255.\n    small_im = transform.resize(im, (im_size,im_size), mode='symmetric', preserve_range=True)\n    X_test[cont, :,:] = small_im\n    cont+=1\n    \nplt.imshow(small_im)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[..., np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-03T14:47:35.920982Z","iopub.status.busy":"2020-12-03T14:47:35.919574Z","iopub.status.idle":"2020-12-03T14:47:36.452657Z","shell.execute_reply":"2020-12-03T14:47:36.451855Z"},"papermill":{"duration":1.258835,"end_time":"2020-12-03T14:47:36.452785","exception":false,"start_time":"2020-12-03T14:47:35.19395","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# create the file to make the sumbission\n\ny_test = model.predict(X_test)\nprint(y_test)\ny_test = [int(round(x[0])) for x in y_test]\n\ndf_output = pd.DataFrame(y_test)\ndf_output.index.name = 'index'\ndf_output.columns = ['prediction']\ndf_output.to_csv('output.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### El model\n\n#### Capes principals\n\nEl model utilitzat consta d'una CNN, com ja s'ha mencionat anteriorment, una xarxa neuronal convolucional té una major capacitat d'obtenir les característiques principals d'una imatge gràcies a les capes de convolució i de Max Pool entre d'altres.\n\nSi parlem del model utilitzat, aquest consta d'una primera part composada per vàries capes de convolució. Els filtres de les capes convolucionals són bastant similars, he decidit fer la xarxa profunda enlloc d'ample. Podem veure en varis papers que les CNN amples són bones en la memorització, cosa que no ens interessa si volem generalitzar el màxim possible.\nEl fet que sigui profunda, ens ajuda a generalitzar i que la CNN aprengui més característiques del problema.\nSi parlem del kernel i padding, aquests han estat estàtics, no els he canviat, 3 i SAME m'ahn funcionat bé. La funció d'activació que utilitzo és la ReLU, aquesta acostuma a ser més eficient (no calcula funcions polinòmiques, bàsicament escull entre dos nombres) i ajuda a que el gradient no desapareixi (vanish).\nSeguides de les capes convolucionals, tenim capes de Max Pooling. Les utilitzo per obtenir la màxima resposta després de fer la convolució, no n'he utilitzat més de dues ja que la mida de la imatge no és gaire gran (64x64).\n\nLa segona part del model es composa per capes Dense o Fully connected (No lineals) que utilitzen la funció d'activació ReLU. Aquest conjunt esta totalment conectat i ens permet passar d'una dimensió 2D (com són les nostres imatges) a un vector.\n\nPer últim, la capa de sortida és una capa Dense també, però utilitza una funció d'activació linear amb una sola sortida que ens donarà un nombre decimal.\nPodriem pensar que aquest problema es tracta d'una classificació, i així el vaig enfocar inicialment, però en realitat el que volem és que la nostra xarxa convolucional pugui comptar quantes persones hi han a la imatge sense cap mena de limitació, cosa que la fa més interessant.\nCom que ens surten valors decimals, el que fem és arrodonir-los al nombre més pròxim i fer conversió a enter.\n\n#### Overfitting\n\n- Per a evitar overfitting he utilitzat les capes Dropout (gairebé després de totes les capes del model) amb un percentatge com a argument, aquesta és una de les formes més senzilles de reduir l'overfitting. Aquestes capes eliminen de forma aleatòria neurones de la xarxa.\n\n- Una altra tècnica utilitzada (en la majoria de capes) és el keras.regularizer. Aquest es basa en la regulació dels pesos de les neurones per a evitar l'overfitting. En el cas del model utilitzat, m'he centrat en el l2, ja que m'ha funcionat millor que l1. Per a ajustar bé el valor de l2 també he hagut d'adaptar-lo bé al meu model per a un bon funcionament, amb 1E-3 ha funcionat força bé.\n\n#### Learning rate\n\nEl learning rate és la quantitat de pesos que s'actualitzen a la xarxa mentres dura l'entrenament. Es considera una bona pràctica fer decaure aquest hiperparàmetre a mesura que avancen les epochs. \n\nAjustar aquest aspecte ajuda al model a que entreni de forma òptima.\n\n#### Tècniques per a millorar el rendiment\n\nUn aspecte a destacar és el data augmentation. Aquesta tècnica ens permet crear imatges noves i els canvis que volem que presenten, rotacions majoritàriament, ajuden al model a generalitzar i a classificar millor en diferents condicions. En el meu cas he utilitzat al voltant d'1 i 4 imatges sintètiques per cada imatge del dataset d'entrenament, d'aquesta manera tenim les fotografies originals i les rotades.\n\nPer a utilitzar eficientment el temps d'execució i que l'entrenament no trigui molta estona, m'he fixat en el loss i el validation loss. Aquest quan no canvia, és a dir, esta comprès en un interval de valors molt petit, l'entrenament pot acabar perfectament.\n\n\n### Conclusions finals\n\nConsidero que el model creat fa la seva funció prou bé, encara que sempre és millorable. He sigut curós en no caure en l'overfitting, pendent de la loss i loss del conjunt de validació, crec que és un hàbit que em serà molt útil en el futur.\n\nHe après el funcionament i objectiu de les CNNs i com poder adaptar-les a un conjunt de dades donat juntament amb els hiperparàmetres corresponents, com el learning rate i l'optimitzador adequat entre d'altres.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}